# Gemini Media MCP

MCP (Model Context Protocol) сервер для анализа мультимедийного контента (изображений, аудио, видео) с помощью Google Gemini AI. Разработан с модульной архитектурой для легкого расширения функциональности.

## Текущий функционал

- **Анализ изображений**
  - Прием изображения от пользователя (путь к файлу на локальной машине)
  - Прием текстового запроса для анализа
  - Гибкая настройка системных промптов:
    - Использование предустановленных промптов
    - Переопределение промпта через аргумент инструмента
    - Использование промпта из файла на стороне пользователя
  - Отдача структурированного ответа (alt-текст и детальный анализ)
- **Поддержка моделей:** Gemini 2.5 Flash, Gemini 2.5 Pro (выбор может быть реализован разными способами, например, через конфигурацию или автоматически моделью)
- **Работа локally** с API ключом пользователя

## Планы на будущее

- Анализ аудио и видео файлов для получения текстовых расшифровок и анализа
- Генерация изображений на основе текстовых запросов
- Генерация аудио контента
- Расширение модульной архитектуры для новых типов медиа

## Требования

- Python 3.8 или выше
- Ключ API Google Gemini (получить можно [здесь](https://makersuite.google.com/app/apikey))

## Установка и запуск

1. **Клонируйте репозиторий:**
   ```bash
   git clone <your-repo-url>
   cd gemini_media_mcp
   ```

2. **Создайте виртуальное окружение (рекомендуется):**
   ```bash
   python -m venv venv
   source venv/bin/activate  # На Windows: venv\Scripts\activate
   ```

3. **Установите зависимости:**
   ```bash
   pip install -r requirements.txt
   ```

4. **Настройте переменные окружения:**
   - Создайте файл `.env` в корне проекта
   - Добавьте в него ваш API ключ:
     ```
     GEMINI_API_KEY="your_gemini_api_key_here"
     ```

5. **Запустите сервер:**
   ```bash
   python server.py
   ```

Сервер запустится в режиме stdio, готовый к работе с MCP-клиентами.

## Конфигурация

### Модели Gemini

Модели, используемые для анализа, могут быть сконфигурированы в файле `config.py`. По умолчанию используются:

- `gemini-2.5-flash`
- `gemini-2.5-pro`

### Промпты

- **Предустановленные промпты:** Хранятся в `config.py` как базовые варианты.
- **Пользовательские промпты:** Передаются непосредственно при вызове инструмента `analyze_image` через аргументы:
  - `user_prompt`: Текстовый запрос для анализа изображения.
  - `system_prompt`: Строка для переопределения системного промпта.
  - `system_prompt_file_path`: Путь к файлу на локальной машине пользователя, содержащему системный промпт.

## Структура проекта

```
gemini_media_mcp/
├── README.MD              # Документация проекта
├── requirements.txt       # Зависимости проекта
├── .env.example          # Пример файла переменных окружения
├── server.py             # Основной файл MCP сервера
├── config.py             # Конфигурация моделей и промптов
├── modules/              # Директория с модулями для разных типов медиа
│   ├── __init__.py
│   ├── image_analysis.py  # Модуль для анализа изображений
│   └── (будущие модули: audio_analysis.py, video_analysis.py)
└── utils/                # Вспомогательные утилиты
    ├── __init__.py
    ├── gemini_client.py   # Обертка для работы с Gemini API
    └── file_utils.py      # Утилиты для работы с файлами
```

## Использование

Сервер предоставляет MCP инструмент `analyze_image` с следующими параметрами:

- `image_path` (string, обязательный): Путь к файлу изображения на локальной машине клиента.
- `user_prompt` (string, опциональный): Пример: "Опиши эмоции на лицах людей в этом фото".
- `system_prompt` (string, опциональный): Кастомный системный промпт для данной операции.
- `system_prompt_file_path` (string, опциональный): Путь к файлу с кастомным системным промптом.

Пример вызова с MCP клиента будет зависеть от реализации клиента. В целом, клиент должен передать эти аргументы, сервер загрузит изображение, сформирует запрос к выбранной модели Gemini и вернет структурированный ответ.

## Лицензия

[Укажите лицензию, если применимо]
